{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e4e4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import copy\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9dfe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5573cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_loader import MIMICDataset,import_data\n",
    "from src.utils import setup_logger\n",
    "from src.training.training_nn import *\n",
    "from src.models.models import ODERNN\n",
    "from src.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f183c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glc_transform(x):\n",
    "    x = x.copy()\n",
    "    x[x > 0] = np.log(x[x > 0]) - np.log(140)\n",
    "    return x\n",
    "\n",
    "def glc_invtransform(x):\n",
    "    x = x.copy()\n",
    "    x = np.exp(x + np.log(140))\n",
    "    return x\n",
    "\n",
    "ginv = glc_invtransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6844be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint_adjoint\n",
    "from torchdiffeq import odeint\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "DT_SCALER = 1 / 24\n",
    "SEQUENCE_LENGTH = 100\n",
    "LAMBDA = 1.0\n",
    "\n",
    "COVAR_INDEX = [0] + list(range(7,25))\n",
    "INSULIN_INDEX = list(range(1,6))\n",
    "\n",
    "def nReLU(input):\n",
    "    return torch.min(input,0)\n",
    "\n",
    "class nReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "\n",
    "    def forward(self, input):\n",
    "        return nReLU(input) \n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for the models\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, p, output_dim, device):\n",
    "        super(Baseline, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.p = p\n",
    "        self.device = device\n",
    "        \n",
    "    def train_single_epoch(self,dataloader,optim,epoch=0):\n",
    "        \"\"\"\n",
    "        Method for model training\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        n_batches = len(dataloader)\n",
    "        print(\"number of batchs: {}\".format(n_batches))\n",
    "        for i, (x, y, msk, dt,msk0) in enumerate(dataloader):\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            y0 = x[:,:,0:1].to(self.device)\n",
    "            dt = dt.to(self.device)\n",
    "            msk = msk.bool().to(self.device)\n",
    "            msk0 = msk0.bool().to(self.device)\n",
    "            optim.zero_grad()\n",
    "            preds,preds0 = self.forward(dt,x,epoch=epoch,training=True)\n",
    "            pred_loss_step = self.loss_fn(preds,y,~msk.view(x.shape[0],-1))\n",
    "            pred0_loss_step = self.loss_fn(preds0,preds,~msk0.view(x.shape[0],-1))\n",
    "            loss_step = pred_loss_step + LAMBDA*pred0_loss_step\n",
    "            loss_step.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.parameters(), 10.0)\n",
    "            optim.step()\n",
    "            loss += loss_step.item()\n",
    "            if i % int(n_batches/4) == 0:\n",
    "                print(\"Batch number: {}\".format(i))\n",
    "                print(\"BATCH_loss : {:05.3f}\".format(loss_step.item()))\n",
    "        loss /= (i + 1)\n",
    "        print(\"EPOCH_loss : {:05.3f}\".format(loss))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def evaluate(self,dataloader,p=0.0):\n",
    "        \"\"\"\n",
    "        Method for model evaluation\n",
    "        \"\"\"\n",
    "        rmse, loss = 0., 0.\n",
    "        N = 0\n",
    "        y_preds = []\n",
    "        y_tests = []\n",
    "        msks = []\n",
    "        #dts = []\n",
    "        with tqdm(total=len(dataloader)) as t:\n",
    "            for i, (x, y, msk, dt, _) in enumerate(dataloader):\n",
    "                N += sum(sum(msk == 0)).item()\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                dt = dt.to(self.device)\n",
    "                # model prediction\n",
    "                y_ = self.forward(dt,x)\n",
    "                y_preds.append([yc.detach().cpu().numpy() for yc in y_]) \n",
    "                y_tests.append(y.cpu().numpy())\n",
    "                msk = msk.bool().to(self.device)\n",
    "                rmse += self.get_sse(y_,y,~msk.view(x.shape[0],-1)).item()\n",
    "                loss += self.loss_fn(y_,y,~msk.view(x.shape[0],-1)).item()\n",
    "                msks.append(msk.cpu().numpy())\n",
    "                t.update()\n",
    "        rmse /= N\n",
    "        loss /= N\n",
    "        rmse = math.sqrt(rmse)\n",
    "        print(\"_rmse : {:05.3f}\".format(rmse))\n",
    "        print(\"_loss : {:05.3f}\".format(loss))\n",
    "        return loss,rmse, y_preds, y_tests, msks\n",
    "\n",
    "    def get_sse(self,y_,y,msk):\n",
    "        \"\"\"\n",
    "        Method for calculation of the sum of squared errors\n",
    "        \"\"\"\n",
    "        if type(y_) == tuple:\n",
    "            y_ = y_[0]\n",
    "        y_ = y_.squeeze(2)\n",
    "        c = torch.log(torch.tensor(140.0))\n",
    "        rmse = torch.sum((torch.exp(y_[msk] + c) - torch.exp(y[msk] + c))**2)\n",
    "        return rmse\n",
    "    \n",
    "    def predict(self,dataloader):\n",
    "        \"\"\"\n",
    "        Predictions that drop masked and concatenate\n",
    "        \"\"\"\n",
    "        mu_preds = []\n",
    "        sigma_preds = []\n",
    "        for i, (x, y, msk, dt, _) in enumerate(dataloader):\n",
    "            x = x.to(self.device)\n",
    "            dt = dt.to(self.device)\n",
    "            # model prediction\n",
    "            mu_,sig_ = self.forward(dt,x)\n",
    "            msk = msk.bool().to(self.device)\n",
    "            mu_preds.append((mu_.squeeze(2)[~msk.bool()]).detach().cpu().numpy())\n",
    "            sigma_preds.append((sig_.squeeze(2)[~msk.bool()]).detach().cpu().numpy())\n",
    "        mu_preds = np.concatenate(mu_preds)\n",
    "        sigma_preds = np.concatenate(sigma_preds)\n",
    "        return mu_preds, sigma_preds\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "\n",
    "class cODERNN_(nn.Module):\n",
    "    \"\"\"\n",
    "    In an ODE-RNN the hidden state h_t of the RNN evolves according to\n",
    "    an ODE. This ODE is a neural network, i.e. dh/dt = ODEFunc(h,x).\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim,hidden_dim,batch_size,device):\n",
    "        super(cODERNN_, self).__init__()\n",
    "\n",
    "        self.x = torch.zeros(batch_size,SEQUENCE_LENGTH,input_dim).to(device)\n",
    "        self.dt = torch.zeros(batch_size,SEQUENCE_LENGTH,1).to(device)\n",
    "        self.device = device\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, hidden_dim),\n",
    "            #nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, dt, y):\n",
    "        return self.net(y)*(self.dt*DT_SCALER)\n",
    "    \n",
    "    def solve_ode(self, z0, t, x):\n",
    "        self.x = x  # overwrites\n",
    "        self.dt = t\n",
    "        #outputs = odeint(self, z0, torch.tensor([0,1.0]).to(self.device),method='euler',options=dict(step_size=0.1))[1]\n",
    "        outputs = odeint(self, z0, torch.tensor([0,1.0]).to(self.device),rtol=1e-3,atol=1e-3)[1]\n",
    "        return outputs\n",
    "\n",
    "class cODERNN(Baseline):\n",
    "    \"\"\"\n",
    "    ODE-RNN\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, p, output_dim, batch_size,device):\n",
    "        Baseline.__init__(self,input_dim, hidden_dim, p, output_dim, device)\n",
    "        # ODE-RNN\n",
    "        self.rnn1 = nn.RNNCell(19, hidden_dim)\n",
    "        nn.init.constant_(self.rnn1.bias_hh, val=0)\n",
    "        nn.init.constant_(self.rnn1.bias_hh, val=0)\n",
    "        nn.init.normal_(self.rnn1.weight_hh, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.rnn1.weight_ih, mean=0, std=0.1)\n",
    "        \n",
    "        self.rnn2 = nn.RNNCell(5+hidden_dim, hidden_dim)\n",
    "        nn.init.constant_(self.rnn2.bias_hh, val=0)\n",
    "        nn.init.constant_(self.rnn2.bias_hh, val=0)\n",
    "        nn.init.normal_(self.rnn2.weight_hh, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.rnn2.weight_ih, mean=0, std=0.1)\n",
    "\n",
    "        self.func = cODERNN_(input_dim,hidden_dim,batch_size,device)\n",
    "        # N(mu,sigma)\n",
    "        # mu\n",
    "        self.output_net_covar = nn.Sequential(\n",
    "            #nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        ).to(device)\n",
    "        self.output_net_insulin = nn.Sequential(\n",
    "            #nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.ReLU()\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, dt, x, p=0.0,epoch=0,training=False):\n",
    "        \n",
    "        T = x.size(1)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        x_insulin = x[:,:,INSULIN_INDEX]\n",
    "        x_covariate = x[:,:,COVAR_INDEX]\n",
    "        \n",
    "        # tempporary solution - put elsewhere...\n",
    "        tt = x_insulin > 0\n",
    "        tt = torch.sum(tt,axis=2)\n",
    "        tt = tt > 0\n",
    "        tt = tt.long()\n",
    "        treatment = tt.unsqueeze(2)\n",
    "\n",
    "        mu_out = torch.zeros(batch_size,T,1,device = self.device)\n",
    "        mu0_out = torch.zeros(batch_size,T,1,device = self.device)\n",
    "        h_covariate_t = torch.zeros(batch_size, self.rnn1.hidden_size,device=self.device)\n",
    "        h_insulin_t = torch.zeros(batch_size, self.rnn2.hidden_size,device=self.device)\n",
    "\n",
    "        for i in range(0,T):\n",
    "            dt_i = (dt[:,i,:][:,1] - dt[:,i,:][:,0]).unsqueeze(1)\n",
    "            treatment_i = treatment[:,i,:]\n",
    "\n",
    "            x_covariate_i = x_covariate[:,i:(i+1),:]\n",
    "            x_insulin_i = x_insulin[:,i:(i+1),:]\n",
    "            \n",
    "            h_covariate_t = h_covariate_t + self.rnn1(x_covariate_i.squeeze(1),h_covariate_t)     \n",
    "            h_insulin_t = h_insulin_t + self.rnn2(torch.cat((x_insulin_i.squeeze(1),h_covariate_t),1),h_insulin_t)     \n",
    "\n",
    "            if training==True:\n",
    "                # immediate forward pass for prediction ('filtering') at t0\n",
    "                mu0_out[:,i:(i+1),:] = self.output_net_covar(h_covariate_t) - treatment_i * self.output_net_insulin(h_insulin_t)\n",
    "            \n",
    "            # forward pass for prediction at t0+\n",
    "            h_covariate_t = self.func.solve_ode(h_covariate_t,dt_i,x_covariate_i)\n",
    "\n",
    "            h_insulin_t = self.func.solve_ode(h_insulin_t,dt_i,x_insulin_i)\n",
    "            mu_tmp = self.output_net_covar(h_covariate_t) - treatment_i * self.output_net_insulin(h_insulin_t)\n",
    "            mu_out[:,i:(i+1),:] = mu_tmp.unsqueeze(1)\n",
    "            \n",
    "        if training == True:\n",
    "            return mu_out,mu0_out\n",
    "        else:\n",
    "            return mu_out\n",
    "    \n",
    "    def loss_fn(self,y_,y,msk):\n",
    "        print(y_.shape)\n",
    "        print(msk.shape)\n",
    "        print(y.shape)\n",
    "        assert y_.shape == y.shape\n",
    "        assert y_.shape == msk.shape\n",
    "        return torch.mean((y_[msk] - y[msk])**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29089e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cODERNN(25, 8, 0.0, 1, 2,\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68248ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1])\n",
      "torch.Size([2, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3259],\n",
       "         [-0.3905]],\n",
       "\n",
       "        [[-0.2422],\n",
       "         [-0.2839]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(torch.randn(2,2,2),torch.randn(2,2,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71cf67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_insulin = torch.randn(2,2,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7106e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = x_insulin > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db8610b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 25])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70461bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15,  8],\n",
       "        [16, 12]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.sum(tt,axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "        tt = tt > 0\n",
    "        tt = tt.long()\n",
    "        treatment = tt.unsqueeze(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9c60d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "        tt = x_insulin > 0\n",
    "        tt = torch.sum(tt,axis=2)\n",
    "        tt = tt > 0\n",
    "        tt = tt.long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39e91f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab1abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
