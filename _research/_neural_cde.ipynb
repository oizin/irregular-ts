{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e33599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchcde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f5de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# A CDE model looks like\n",
    "#\n",
    "# z_t = z_0 + \\int_0^t f_\\theta(z_s) dX_s\n",
    "#\n",
    "# Where X is your data and f_\\theta is a neural network. So the first thing we need to do is define such an f_\\theta.\n",
    "# That's what this CDEFunc class does.\n",
    "# Here we've built a small single-hidden-layer neural network, whose hidden layer is of width 128.\n",
    "######################\n",
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9150d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Next, we need to package CDEFunc up into a model that computes the integral.\n",
    "######################\n",
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, interpolation=\"linear\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        if self.interpolation == 'cubic':\n",
    "            X = torchcde.NaturalCubicSpline(coeffs)\n",
    "        elif self.interpolation == 'linear':\n",
    "            X = torchcde.LinearInterpolation(coeffs)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'linear' and 'cubic' interpolation methods are implemented.\")\n",
    "\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func,\n",
    "                              t=X.interval)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
